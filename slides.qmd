---
title: "Spatial Data Workshop"
subtitle: "2023 EPA R User Group Workshop"
date: October 18, 2023
format:
  revealjs:
    author: 
      - "Marc Weber"
      - "Michael Dumelle"
    institute: 
      - "EPA (USA)"
      - "EPA (USA)"
    footer: "Spatial Data Workshop"
    slide-number: true
    preview-links: true
    transition: fade
    theme: [default, slides.scss]
    smaller: false
    auto-stretch: true
    code-link: true
    incremental: false
execute: 
  echo: true
embed-resources: true
bibliography: references.bib
---

```{r}
#| label: setup
#| include: false

# set width of code output
options(width = 80)

# load background packages
library(countdown)
library(ggplot2)
```

## Welcome!

1. Please visit INSERT LINK HERE to view the workshop's accompanying workbook

2.  Install and load R packages (INSERT LINK HERE TO SECTION IN WORKBOOK)

3. (Optional) Download the workshop slides (instructions in the workbook's Introduction)

4. Follow along and have fun!

## Who Are We?

Marc Weber is a geographer at the Pacific Ecological Systems Division (PESD) at the United States Environmental Protection Agency (USEPA). His work supports various aspects of the USEPA's National Aquatic Resource Surveys (NARS), which characterize the condition of waters across the United States, as he helped develop and maintains the StreamCat and LakeCat datasets.  His work focuses on spatial analysis in R and Python, Geographic Information Science (GIS), aquatic ecology, remote sensing, open source science and environmental modeling.

## Who Are We?

Michael Dumelle is a statistician for the United States Environmental Protection Agency (USEPA). He works primarily on facilitating the survey design and analysis of USEPA's National Aquatic Resource Surveys (NARS), which characterize the condition of waters across the United States. His primary research interests are in spatial statistics, survey design, environmental and ecological applications, and software development.

## Disclaimer

The views expressed in this workshop are those of the authors and do not necessarily represent the views or policies of the U.S. Environmental Protection Agency or the U.S. National Oceanic and Atmospheric Administration. Any mention of trade names, products, or services does not imply an endorsement by the U.S. government, the U.S. Environmental Protection Agency, or the U.S. National Oceanic and Atmospheric Administration. The U.S. Environmental Protection Agency and the U.S. National Oceanic and Atmospheric Administration do not endorse any commercial products, services, or enterprises.

## What Will We Cover?

* Foundations of spatial data
* Visualizing spatial data
* Geoprocessing spatial data
* Advanced applications
* Focus on the **R** computing language

# Foundations

## Goals

::: goals
1. Understand fundamental spatial data structures and libraries in **R**.
2. Become familiar with coordinate reference systems.
3. Geographic I/O (input/output).
:::

## Data Structures

* Review data structures section in workbook
* Cover vectors, matrices, arrays, lists, data frames, etc.
* Cover data frame manipulation using [tidyverse](https://www.tidyverse.org/) functions and the pipe operator (`%>%` or `|>`)

## Why R for Spatial Data Analysis?

* Lightweight, open-source, and cross-platform
* Provides tools for automation and reproducibility
* Seamlessly integrates spatial data analysis and statistical analysis in one environment
* Handles vector and raster data

## R Drawbacks for GIS Work

* R is less interactive than desktop applications like ArcGIS or QGIS
* Handling coordinate reference systems is more challenging
* In-memory analysis can be prohibitive for large data
* Steep learning curve

## A Motivating Example

* Simple, expressive code

```{r}
#| warning: false
library(tmap)
library(tmaptools)
library(dplyr)

# find my town!
my_town <- tmaptools::geocode_OSM("Corvallis OR USA", as.sf = TRUE)
glimpse(my_town)
```

## Your Turn

::: task
1. What does `::` do?
2. What does `geocode_OSM()` do?
3. Explain how the code runs together using the  `|>` chaining operator
4. What is `glimpse()`?  How is it useful compared to `head()`?
:::

```{r}
#| echo: false

countdown(minutes = 5)
```

## A Choropleth Map

* A choropleth map is a map that connects statistical summaries to geographic characteristics
* The `tigris` package can retrieve census, county, and state boundaries as vector `sf` data

```{r}
#| label: fig-tmapexample
#| fig-cap: "Distribution of Oregon counties."
#| output-location: slide
#| fig-width: 8
#| results: hide
#| message: false
#| warning: false

library(tigris)
library(sf)
counties <- counties("Oregon", cb = TRUE)
counties$area <- as.numeric(st_area(counties))
glimpse(counties)

tm_shape(counties) +
  tm_polygons("area", style="quantile", title="Area of Oregon Counties")
```


## Your Turn

::: task
Create and explore an interactive map of `my_town` by running
```{r}
#| eval: false
library(mapview)
mapviewOptions(fgb=FALSE)
mapview(my_town, col="red", col.regions = "red") +
  mapview(counties, alpha.regions = .1)
```

:::

```{r}
#| echo: false
#| results: hide
#| message: false
#| warning: false

library(mapview)
countdown(minutes = 4)
```

## Spatial Data Structures

* Spatial data structures are primarily organized through:

1. GDAL [link here](https://gdal.org/): For raster and feature abstraction and processing
2. PROJ [link here](https://proj.org/): For coordinate transformations and projections
3. GEOS [link here](https://libgeos.org/): For spatial operations (e.g., calculating buffers or centroids) on data with a projected coordinate reference system (CRS)

* We explore these core libraries throughout the workshop

## Types of Spatial Data

* Vector data are comprised of points, lines, and polygons that represent discrete spatial entities (e.g., river, wtaershed, stream gauge)
* Raster data divide space into small rectangles (pixels) that represent spatially continuous phenomena like elevation or precipitation

```{r}
#| label: fig-vectorraster
#| fig-cap: "Vector and raster data."
#| fig-align: center
#| out-width: "100%"
#| echo: false

knitr::include_graphics("img/09-vec-raster.jpg")
```


## Vector Data Model

* Vector data are described using simple features
* Simple features is a standard way to specify how two-dimensional geometries are represented, stored in and retrieved from databases, and which geometric operations can be performed
* Provides framework for extending spatial `POINTS` to `LINES` and `POLYGONS`

```{r}
#| label: fig-sfmodel
#| fig-cap: "The simple features data model."
#| fig-align: center
#| echo: false
#| out-width: "100%"

knitr::include_graphics("img/09-sf-model.png")
```

## The `sf` package

* We use the `sf` package to work with spatial vector data in **R**
* Learn more about `sf` at their website [r-spatial.github.io/sf](r-spatial.github.io/sf) and/or by running
```{r}
#| eval: false

vignette(package = "sf") # see which vignettes are available
vignette("sf1")          # open the introduction vignette
```

## `sf` Primitives

* There are three basic `geometric` primitives with corresponding `sf` functions to create them:

1. `POINT`: created with `st_points()`
2. `LINESTRING`: created with `st_linestring()`
3. `POLYGON`: created with `st_polygon()`

* More complex simple feature geometries are built up using `st_multipoint()`, `st_multilinestring()`, `st_multipolygon()`, and `st_geometrycollection()`
* Building blocks for more complicated/large data structures

## `POINT`s

* Points in `sf` are composed of coordinate pairs and a coordinate reference system
* Points have no length or area
```{r}
# create sf object as point
pt1 <- st_point(c(1,3))
pt2 <- st_point(c(2,1))
pt3 <- st_point(c(3,2))
sf_point <- st_sfc(pt1, pt2, pt3)
```

```{r}
#| label: fig-sfpoint
#| fig-cap: "sf `POINT`"
#| output-location: slide

ggplot(sf_point) + 
  geom_sf(color = "red") +
  labs(x = "X", y = "Y")
```

## `LINESTRING`s

* An ordered sequence of two or more `POINT`s
* Points in a line are called verticies (or nodes)
* Linestrings have length but no area

```{r}
# create sf object as linestring
line1 <- sf::st_linestring(rbind(pt1, pt2))
line2 <- sf::st_linestring(rbind(pt2, pt3))
sf_linestring <- st_sfc(line1, line2)
```

```{r}
#| label: fig-sflinestring
#| fig-cap: "sf `LINESTRING`"
#| output-location: slide

ggplot(sf_linestring) + 
  geom_sf() +
  labs(x = "X", y = "Y")
```

## `POLYGON`s

* Four or more points with the same starting and ending point
* Has length and area


```{r}
pt4 <- pt1
poly1 <- st_polygon(list(rbind(pt1, pt2, pt3, pt4)))
sf_polygon <- st_sfc(poly1)

# dimension
sf::st_dimension(sf_polygon)
```

```{r}
#| label: fig-sfpolygon
#| fig-cap: "sf `POLYGON`"
#| output-location: slide

ggplot(sf_polygon) + 
  geom_sf(fill = "grey")
```

## Putting Them All Together

```{r}
#| label: fig-sfallshape
#| fig-cap: "sf `POINT`, `LINESTRING`, and `POLYGON` overlain"
#| output-location: slide

ggplot() +
  geom_sf(data = sf_point, color = "red") +
  geom_sf(data = sf_linestring) +
  geom_sf(data = sf_polygon, fill = "grey")
```

## Spatial Data Frames

* `sf` objects combine `data.frame` attributes with `POINT`, `LINESTRING`, and `POLYGON` building blocks (these are the `geometry`)
* Also characterize dimensionality, bounding box, coordinate reference system, attribute headers

```{r}
#| warning: false
#| message: false
#| output-location: slide

library(spData)
data("us_states")
print(us_states)
```

## Spatial Data Frames

```{r}
#| label: fig-sfstructure
#| fig-cap: "The simple features data structure."
#| fig-align: center
#| echo: false
#| out-width: "100%"

knitr::include_graphics("img/sf_structure.png")
```

## Your Turn

::: task
So far we have explored plotting using `ggplot()`, but you can also use `sf`'s base plotting via `plot()`. Read more about plotting in `sf` by running `?plot.sf` and then make an appropriate plot of the `us_states` data.
:::

